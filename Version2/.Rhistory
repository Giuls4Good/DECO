sum((X[,x] - mean(X[,x]))^2)
)
}
)
while(looping){
#update each beta_i in turn
beta2<-sapply(1:p,
function(i){
lambda_scaled<-lambda*vars_inverses[[i]]
#update beta_i
a<-(t(X[,i])%*%(Y-X[,-i]%*%betaVec[-i]))*vars_inverses[[i]]
if(a>lambda){
betaVec[i]<<-(a-lambda)
}else if(abs(a) <= lambda){
betaVec[i]<<- 0
}else{  #if a< -lambda
betaVec[i]<<- a+lambda
}
}
)
#Make sure that your convergence criterion is achieved
if(min(abs(beta-beta2))<prec3){   #if the minimum of the absolute differences between the last two iterations < prec2
looping<-FALSE
}
#make sure you refer to the up-to-date values next iteration/at output
betaVec<<-beta2
}
dim(X)
a
lambda
a<-(t(X[,i])%*%(Y-X[,-i]%*%betaVec[-i]))*vars_inverses[[i]]
p
vars_inverses<-sapply(1:p,
function(x){
1/(
(1/n)*
sum((X[,x] - mean(X[,x]))^2)
)
}
)
vars_inverses
while(looping){
#update each beta_i in turn
beta2<-sapply(1:p,
function(i){
lambda_scaled<-lambda*vars_inverses[[i]]
#update beta_i
a<-(t(X[,i])%*%(Y-X[,-i]%*%betaVec[-i]))*vars_inverses[[i]]
if(a>lambda){
betaVec[i]<<-(a-lambda)
}else if(abs(a) <= lambda){
betaVec[i]<<- 0
}else{  #if a< -lambda
betaVec[i]<<- a+lambda
}
}
)
#Make sure that your convergence criterion is achieved
if(min(abs(beta-beta2))<prec3){   #if the minimum of the absolute differences between the last two iterations < prec2
looping<-FALSE
}
#make sure you refer to the up-to-date values next iteration/at output
betaVec<<-beta2
}
a>lambda
a
a<-(t(X[,i])%*%(Y-X[,-i]%*%betaVec[-i]))*vars_inverses[[i]]
i
rm(i)
p<-ncol(X)  #get the number of rows for the (local) regression matrix
betaVec<-solve(crossprod(X, X))%*%(t(X)%*%Y) #initialize using OLS!
looping<-TRUE #boolean checking if we still need to loop
vars_inverses<-sapply(1:p,
function(x){
1/(
(1/n)*
sum((X[,x] - mean(X[,x]))^2)
)
}
)
while(looping){
#update each beta_i in turn
beta2<-sapply(1:p,
function(i){
lambda_scaled<-lambda*vars_inverses[[i]]
#update beta_i
a<-(t(X[,i])%*%(Y-X[,-i]%*%betaVec[-i]))*vars_inverses[[i]]
if(a>lambda){
betaVec[i]<<-(a-lambda)
}else if(abs(a) <= lambda){
betaVec[i]<<- 0
}else{  #if a< -lambda
betaVec[i]<<- a+lambda
}
}
)
#Make sure that your convergence criterion is achieved
if(min(abs(beta-beta2))<prec3){   #if the minimum of the absolute differences between the last two iterations < prec2
looping<-FALSE
}
#make sure you refer to the up-to-date values next iteration/at output
betaVec<<-beta2
}
betaVec
p<-ncol(X)  #get the number of rows for the (local) regression matrix
betaVec<-rep(1,p)#solve(crossprod(X, X))%*%(t(X)%*%Y) #initialize using OLS!
looping<-TRUE #boolean checking if we still need to loop
vars_inverses<-sapply(1:p,
function(x){
1/(
(1/n)*
sum((X[,x] - mean(X[,x]))^2)
)
}
)
while(looping){
#update each beta_i in turn
beta2<-sapply(1:p,
function(i){
lambda_scaled<-lambda*vars_inverses[[i]]
#update beta_i
a<-(t(X[,i])%*%(Y-X[,-i]%*%betaVec[-i]))*vars_inverses[[i]]
if(a>lambda){
betaVec[i]<<-(a-lambda)
}else if(abs(a) <= lambda){
betaVec[i]<<- 0
}else{  #if a< -lambda
betaVec[i]<<- a+lambda
}
}
)
#Make sure that your convergence criterion is achieved
if(min(abs(beta-beta2))<prec3){   #if the minimum of the absolute differences between the last two iterations < prec2
looping<-FALSE
}
#make sure you refer to the up-to-date values next iteration/at output
betaVec<<-beta2
}
#test data
n<-100
p<-500
m<-1
sigma<-1
lambda<-0.03
r<-0.01
set.seed(100)
X<-matrix(rnorm(n*p, sd=1), nrow=n)
set.seed(1000)
eps<-rnorm(n, mean = 0, sd = sigma)
set.seed(5000)
activeCoefs<-sample(c(0,1),p, prob=c(0.9, 0.1), replace=TRUE)  ##get coefficients that impact Y
set.seed(10000)
coefs<-activeCoefs*1
Y<-X%*%coefs + eps
X<-X[,1:20]
p<-ncol(X)  #get the number of rows for the (local) regression matrix
betaVec<-rep(1,p)#solve(crossprod(X, X))%*%(t(X)%*%Y) #initialize using OLS!
looping<-TRUE #boolean checking if we still need to loop
vars_inverses<-sapply(1:p,
function(x){
1/(
(1/n)*
sum((X[,x] - mean(X[,x]))^2)
)
}
)
while(looping){
#update each beta_i in turn
beta2<-sapply(1:p,
function(i){
lambda_scaled<-lambda*vars_inverses[[i]]
#update beta_i
a<-(t(X[,i])%*%(Y-X[,-i]%*%betaVec[-i]))*vars_inverses[[i]]
if(a>lambda){
betaVec[i]<<-(a-lambda)
}else if(abs(a) <= lambda){
betaVec[i]<<- 0
}else{  #if a< -lambda
betaVec[i]<<- a+lambda
}
}
)
#Make sure that your convergence criterion is achieved
if(min(abs(beta-beta2))<prec3){   #if the minimum of the absolute differences between the last two iterations < prec2
looping<-FALSE
}
#make sure you refer to the up-to-date values next iteration/at output
betaVec<<-beta2
}
warnings()
beta
beta2
p
p<-ncol(X)  #get the number of rows for the (local) regression matrix
betaVec<-rep(1,p)#solve(crossprod(X, X))%*%(t(X)%*%Y) #initialize using OLS!
looping<-TRUE #boolean checking if we still need to loop
vars_inverses<-sapply(1:p,
function(x){
1/(
(1/n)*
sum((X[,x] - mean(X[,x]))^2)
)
}
)
while(looping){
#update each beta_i in turn
beta2<-sapply(1:p,
function(i){
lambda_scaled<-lambda*vars_inverses[[i]]
#update beta_i
a<-(t(X[,i])%*%(Y-X[,-i]%*%betaVec[-i]))*vars_inverses[[i]]
if(a>lambda){
betaVec[i]<<-(a-lambda)
}else if(abs(a) <= lambda){
betaVec[i]<<- 0
}else{  #if a< -lambda
betaVec[i]<<- a+lambda
}
}
)
#Make sure that your convergence criterion is achieved
if(min(abs(betaVec-beta2))<prec3){   #if the minimum of the absolute differences between the last two iterations < prec2
looping<-FALSE
}
#make sure you refer to the up-to-date values next iteration/at output
betaVec<<-beta2
}
betaVec
plot(betaVec)
p<-ncol(X)  #get the number of rows for the (local) regression matrix
betaVec<-rep(1,p)#solve(crossprod(X, X))%*%(t(X)%*%Y) #initialize using OLS!
looping<-TRUE #boolean checking if we still need to loop
vars_inverses<-sapply(1:p,
function(x){
1/(
sum((X[,x] - mean(X[,x]))^2)
)
}
)
while(looping){
#update each beta_i in turn
beta2<-sapply(1:p,
function(i){
lambda_scaled<-lambda*vars_inverses[[i]]
#update beta_i
a<-(t(X[,i])%*%(Y-X[,-i]%*%betaVec[-i]))*vars_inverses[[i]]
if(a>lambda){
betaVec[i]<<-(a-lambda)
}else if(abs(a) <= lambda){
betaVec[i]<<- 0
}else{  #if a< -lambda
betaVec[i]<<- a+lambda
}
}
)
#Make sure that your convergence criterion is achieved
if(min(abs(betaVec-beta2))<prec3){   #if the minimum of the absolute differences between the last two iterations < prec2
looping<-FALSE
}
#make sure you refer to the up-to-date values next iteration/at output
betaVec<<-beta2
}
plot(betaVec)
abline(h=0)
lambda
lambda<-0.5
p<-ncol(X)  #get the number of rows for the (local) regression matrix
betaVec<-rep(1,p)#solve(crossprod(X, X))%*%(t(X)%*%Y) #initialize using OLS!
looping<-TRUE #boolean checking if we still need to loop
vars_inverses<-sapply(1:p,
function(x){
1/(
sum((X[,x] - mean(X[,x]))^2)
)
}
)
while(looping){
#update each beta_i in turn
beta2<-sapply(1:p,
function(i){
lambda_scaled<-lambda*vars_inverses[[i]]
#update beta_i
a<-(t(X[,i])%*%(Y-X[,-i]%*%betaVec[-i]))*vars_inverses[[i]]
if(a>lambda){
betaVec[i]<<-(a-lambda)
}else if(abs(a) <= lambda){
betaVec[i]<<- 0
}else{  #if a< -lambda
betaVec[i]<<- a+lambda
}
}
)
#Make sure that your convergence criterion is achieved
if(min(abs(betaVec-beta2))<prec3){   #if the minimum of the absolute differences between the last two iterations < prec2
looping<-FALSE
}
#make sure you refer to the up-to-date values next iteration/at output
betaVec<<-beta2
}
betaVec
plot(betaVec)
abline(h=0)
lambda<-0.03
p<-ncol(X)  #get the number of rows for the (local) regression matrix
betaVec<-rep(1,p)#solve(crossprod(X, X))%*%(t(X)%*%Y) #initialize using OLS!
looping<-TRUE #boolean checking if we still need to loop
vars_inverses<-sapply(1:p,
function(x){
1/(
sum((X[,x] - mean(X[,x]))^2)
)
}
)
while(looping){
#update each beta_i in turn
beta2<-sapply(1:p,
function(i){
lambda_scaled<-lambda*vars_inverses[[i]]
#update beta_i
a<-(t(X[,i])%*%(Y-X[,-i]%*%betaVec[-i]))*vars_inverses[[i]]
if(a>lambda){
betaVec[i]<<-(a-lambda)
}else if(abs(a) <= lambda){
betaVec[i]<<- 0
}else{  #if a< -lambda
betaVec[i]<<- a+lambda
}
}
)
#Make sure that your convergence criterion is achieved
if(min(abs(betaVec-beta2))<prec3){   #if the minimum of the absolute differences between the last two iterations < prec2
looping<-FALSE
}
#make sure you refer to the up-to-date values next iteration/at output
betaVec<<-beta2
}
plot(betaVec)
abline(h=0)
?glmnet
library(glmnet)
?glmnet
glmnet(X, Y, intercept=FALSE, lambda=lambda, nlambda=1)
plot(coef(glmnet(X, Y, intercept=FALSE, lambda=lambda, nlambda=1)))
abline(h=0)
p<-ncol(X)  #get the number of rows for the (local) regression matrix
betaVec<-solve(crossprod(X, X))%*%(t(X)%*%Y) #initialize using OLS!rep(1,p)#
looping<-TRUE #boolean checking if we still need to loop
vars_inverses<-sapply(1:p,
function(x){
1/(
sum((X[,x] - mean(X[,x]))^2)
)
}
)
while(looping){
#update each beta_i in turn
beta2<-sapply(1:p,
function(i){
lambda_scaled<-lambda*vars_inverses[[i]]
#update beta_i
a<-(t(X[,i])%*%(Y-X[,-i]%*%betaVec[-i]))*vars_inverses[[i]]
if(a>lambda){
betaVec[i]<<-(a-lambda)
}else if(abs(a) <= lambda){
betaVec[i]<<- 0
}else{  #if a< -lambda
betaVec[i]<<- a+lambda
}
}
)
#Make sure that your convergence criterion is achieved
if(min(abs(betaVec-beta2))<prec3){   #if the minimum of the absolute differences between the last two iterations < prec2
looping<-FALSE
}
#make sure you refer to the up-to-date values next iteration/at output
betaVec<<-beta2
}
plot(betaVec2)
plot(betaVec)
abline(h=0)
devtools::load_all('~/Modules/Module4/Implementation/Version2')
devtools::load_all('~/Modules/Module4/Implementation/Version2')
?Coordinate_Descent
?DECO
?DECO_LASSO
.C("myFun2")
.C("myFun1", 3, 4)
.C("myFun1", as.integer(3), as.double(4))
.C("myFun", as.integer(3), as.double(4))
devtools::load_all('~/Modules/Module4/Implementation/Version2')
devtools::load_all('~/Modules/Module4/Implementation/Version2')
library(rcpp)
library(RCPP)
Rcpp
library(Rcpp)
devtools::load_all('~/Modules/Module4/Implementation/Version2')
devtools::load_all('~/Modules/Module4/Implementation/Version2')
.C("timesTwo", x=3)
.C("timesTwo", x=as.vector(1:10))
timesTwo(4)
timesTwo(as.vector(1:5))
devtools::load_all('~/Modules/Module4/Implementation/Version2')
devtools::load_all('~/Modules/Module4/Implementation/Version2')
timesTwo(3:5)
timesTwo(3)
getwd()
devtools::load_all('~/Modules/Module4/Implementation/Version2')
#test data
n<-1000
p<-500
m<-1
sigma<-1
lambda<-3
r<-0.01
set.seed(100)
X<-matrix(rnorm(n*p, sd=1), nrow=n)
set.seed(1000)
eps<-rnorm(n, mean = 0, sd = sigma)
set.seed(5000)
activeCoefs<-sample(c(0,1),p, prob=c(0.9, 0.1), replace=TRUE)  ##get coefficients that impact Y
set.seed(10000)
coefs<-activeCoefs*1
Y<-X%*%coefs + eps
?benchmark
benchmark(solverTester(X,Y), solve(crossprod(X, X))%*%(t(X)%*%Y), replications=10)
#test data
n<-2000
p<-1000
m<-1
sigma<-1
lambda<-3
r<-0.01
set.seed(100)
X<-matrix(rnorm(n*p, sd=1), nrow=n)
set.seed(1000)
eps<-rnorm(n, mean = 0, sd = sigma)
set.seed(5000)
activeCoefs<-sample(c(0,1),p, prob=c(0.9, 0.1), replace=TRUE)  ##get coefficients that impact Y
set.seed(10000)
coefs<-activeCoefs*1
Y<-X%*%coefs + eps
benchmark(solverTester(X,Y), solve(crossprod(X, X))%*%(t(X)%*%Y), replications=3)
benchmark(solverTester(X,Y), glmnet(X,Y,lambda=lambda,intercept=FALSE, thres=0.0001), replications=3)
?glmnet
?coordinateDescent
b1<-coordinateDescent(X,Y,0.5,0.0001,1000)
b2<-glmnet(X,Y, lambda=1, thres=0.0001)
plot(ts(b1))
line(b2, col=2)
lines(b2, col=2)
lines(ts(b2), col=2)
lines(ts(coef(b2)), col=2)
lines(ts(as.vector(coef(b2))), col=2)
plot((b1), type="p")
points(as.vector(coef(b2)), col=2)
b2<-glmnet(X,Y, lambda=2, thres=0.0001)
plot((b1), type="p")
points(as.vector(coef(b2)), col=2)
?scle
?scale
X<-scale(X, center=TRUE, scale=TRUE)
Y<-scale(Y, center=TRUE, scale=TRUE)
b2<-glmnet(X,Y, lambda=1, thres=0.0001)
b1<-coordinateDescent(X,Y,0.5,0.0001,1000)
plot((b1), type="p")
points(as.vector(coef(b2)), col=2)
?glmnet
#test data
n<-2000
p<-10
m<-1
sigma<-1
lambda<-3
r<-0.01
set.seed(100)
X<-matrix(rnorm(n*p, sd=1), nrow=n)
set.seed(1000)
eps<-rnorm(n, mean = 0, sd = sigma)
set.seed(5000)
activeCoefs<-sample(c(0,1),p, prob=c(0.9, 0.1), replace=TRUE)  ##get coefficients that impact Y
set.seed(10000)
coefs<-activeCoefs*1
Y<-X%*%coefs + eps
X<-scale(X, center=TRUE, scale=TRUE)
Y<-scale(Y, center=TRUE, scale=TRUE)
glmnet(X,Y,lambda=lambda,intercept=FALSE, thres=0.0001)
plot(coef(glmnet(x = X, y = Y, lambda = lambda, intercept = FALSE)))
activeCoefs
#test data
n<-2000
p<-10
m<-1
sigma<-1
lambda<-3
r<-0.01
set.seed(100)
X<-matrix(rnorm(n*p, sd=1), nrow=n)
set.seed(1000)
eps<-rnorm(n, mean = 0, sd = sigma)
set.seed(5000)
activeCoefs<-sample(c(0,1),p, prob=c(0.9, 0.1), replace=TRUE)  ##get coefficients that impact Y
X[,which(activeCoefs ==1)]<-X[,which(activeCoefs ==1)]*10##multiply the magnitude of X at the active regressors with 10
set.seed(10000)
coefs<-activeCoefs*1
Y<-X%*%coefs + eps
plot(coef(glmnet(x = X, y = Y, lambda = lambda, intercept = FALSE)))
activeCoefs
lambda
lambda<-0.3
plot(coef(glmnet(x = X, y = Y, lambda = lambda, intercept = FALSE)))
coef(glmnet(x = X, y = Y, lambda = lambda, intercept = FALSE))[5]
devtools::load_all('~/Modules/Module4/Implementation/Version2')
